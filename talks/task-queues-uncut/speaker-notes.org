* Очереди задач без купюр
  Всем привет, меня зовут Малышев Артем.  Я работаю компании Positive
  Technologies и сегодня расскажу вам про очереди задач.  В прошлом
  году на вопрос "А кто вообще знает, что это такое?" тут весь зал
  поднял руки.  Поэтому я осмелюсь предположить что большая часть
  аудитории с обсуждаемой темой знакома.  Так почему же без купюр?
  Неточтобы я тут собрался материться.  Просто хочется раскрыть вам
  эту тему с более другой стороны.  Поговорим о том как и почему
  очереди задач устроены.  Прежде всего хочу предупредить, никакого
  рассказа про серебрянные пули не будет.  Я не обвиняю и не
  оправдываю ни один из выбранных подходов.  Я просто расскажу вам как
  обстоят дела, а дальше вы сами решите как будете с этим жить.

* Celery
  Итак главный гость нашей программы - Celery.  Распределённая очередь
  задач, написанная Аском Солемом Хоуэлом.  Умеет использовать всё до
  чего дотянется и как broker и как backend.  Имеет непревзойдённое
  колличество фич.  Думаю все с этой штукой знакомы и очень многие
  используют в продакшене.  Все обсуждаемые вопросы я буду
  рассматривать с точки зрения rabbitmq и redis (и в роли broker'а и в
  роли backend'а).

* RQ
  В левом углу ринга RQ, он же Redis Queue.  Наиболее популярная
  альтернатива Celery.  Автор RQ поначалу что-то контрибъютил в
  Celery, но потом видимо потерял надежду и написал свой пакет.  Он в
  отличие о Celery умеет только в redis.  Основывается на простой
  архитектуре и хороших намерениях и не разделяет понятия broker'а и
  backend'а, используя лишь одну сущьность.  И так, прежде чем
  рассматривать как очереди задач реализуют свои парадигмы с помощью
  сторонних инструментов - обсудим, а что эти инструменты вообще
  умеют.

* rabbitmq
  RabbitMQ broker сообщений работающий по протоколу AMQP.  Девиз
  проекта "Messaging that just works".  Основные приметивы - очереди,
  exchange'и и биндинги одного к другому.  Если мы выступаем в роли
  publisher'а - мы можем отправить сообщение в exchange и он тут же
  положет его в очередь.  Как именно он это сделает - зависит от типа
  самого exchange и от биндингов, которые существуют между ним и
  очередями.  У самого rabbitmq есть механизм контроля особо активных
  паблишеров.  Он может сказать одному из них: "Помолчи."  И до тех
  пор пока rabbitmq не скажет тому же паблишеру: "Продолжай", каждый
  порядочный паблишер будет молчать.

* on the other side
  Если же мы выступаем в роли consumer'а, то от нас уже мало что
  зависит.  RabbitMQ сам решает когда и как он будет назначать на нас
  сообщения.  Consumer в свою очередь обязуется подтверждать получение
  сообщения только в том случае, если он смог успешно его обработать.
  При этом значение слова "успешно" трактуется исключительно самим
  consumer'ом и пользователем его API.  Как только rabbitmq получил
  acknowledge по сообщению - он волен его удалить.  У самого
  consumer'а имеется механизм обратной связи с rabbitmq - так
  называемый Quality of Service.  Это механизм, через который consumer
  может сообщить кролику сколько сумарно неподтверждённых сообщений он
  может иметь.  Как только это количество стало равно пороговому
  rabbitmq перестаёт назначать сообщения, до тех пор пока не придёт
  acknowledge хотябы на одно из них.

* amqp
  Теперь немного более детально про сам протокол общения между
  клиентами и rabbit'ом.  У нас в руках асинхронный протокол с
  поддержкой мультиплексирования.  Минимально возможной
  последовательностью байт является фрейм.  Это оформленный пакет,
  который несёт в себе метод, который необходимо применить к очереди,
  эксченджу или биндингу.  Это может быть фрейм с контентом, который
  необходимо доставить другому клиенту.  Или же это может быть
  heartbeet фрэйм для проверки активности соединения.  Ну и чтобы
  firewall не смущать.  Логическая последовательность фреймов
  называется каналом.  Канал является примитивом мультиплексирования и
  позволяет обрабатывать несколько виртуальный соединений в рамках
  одного физического.  Последовательность фреймов в сокете можем быть
  произвольная, но в рамках канала строго определённая.  Результат
  операции запущенной позже другой может придти раньше.

* redis
  Redis в свою очередь к очередям сообщений отнощение имеет только
  косвенное, но это судя по всему никого не останавливает.  Редиска
  является key value хранилищем.  Хранимые значения могут быть самые
  разные.  Чиселки, строки, словари и списки.  Вот из таких приметивов
  и строится нечто похожее на broker сообщений.  Протокол общения
  рэдиса с клиентами самый простой - записали команду, прочитали
  ответ.  Пока команда не выполнилась - ничего другого ждать не стоит.
  Сами команды в рэдис слать можно хоть через telnet.

* submit a task
  Двайте посмотрим как в очереди задач эти самые задачи попадают.

* celery + rabbitmq
  (скриншот из rabbitmq manager) В случае с rabbitmq и celery всё
  просто - в broker в соответствие с celery routing попадает
  сообщение.  В payload фрэймах приходит необходимая информация - id
  задачи, какую задачу с какими аргументами запустить, что делать с
  результатом дальше.  Информация необходимая broker'у храниться в
  AMQP заголовках.  При этом payload сериализуется одним из выбранных
  нами способов.  Это могут быть форматы pickle, json, yaml или
  msgpack.  В случае pickle и msgpack сообщение дополнительно
  кодируется в base64.  Тоже самое происходит при применение сжатия
  gzip.  Самой задачей является наименование её внутри application'а
  celery.

* celery + redis
  (lrange по очереди) Celery собирает сообщение которое также состоит из служебной
  информации и поля payload.  Формат самого сообщения - всегда JSON,
  формат в котором мы хотим хранить payload можно выбрать по своему
  усмотрению.  Сфорированное сообщение в виде строки попадает в список
  соответствующий названию очереди.

* rq
  (lrange по очереди, hgetall по задаче)  RQ в данном случае ведёт
  себя похожим образом.  В список соответствующий очереди попадает
  id задачи.  По ключу с id задачи храниться хэшь таблица с полями
  самой задачи.  Какую функцию с какими аргументами вызвать.  Когда
  задача была создана, запланирована и так далее.  RQ позволяет
  использовать только pickle.  Аргументы как позиционные, так и
  keyword полностью сохраняются в сообщение.  Если мы ставим в очередь
  вызов метода, то сохраняется наименование метода и сам инстанс
  полностью.  Если вызывается функция, то сохраняется её полное имя
  (включая модуль).

* получение задач
  (две команды стартовать воркер)  Что же происходит с задачей, когда
  она попадает в сам воркер?  Здесь как и следовало ожидать тоже
  имеется существенная разница в поведении.

* celery + rabbit
  (скрин с ready, unacked и total) В зависимости от настройки
  CELERY_ACKS_LATE после того как сообщение было доставлено
  consumer'у, воркер может подтвердить сообщение сразу или только по
  окончанию выполнения задачи.

* celery + redis
  Как только Celery забрала элемент из списка - задача полностью
  пропадает из очереди.  Воркер разбирает сообщение, достаёт task.id
  из поля payload и снова сохраняет всю задачу в хэшэ "unacked" по
  ключу соответствующему номеру задачи.  Далее воркер начинает
  обработку задачи.  По окончанию ключ с задачей удаляется из хэша.
  Отличительной особенностью здесь является что celery может получить
  всю задачу сразу, т.к. нет необходимости отдельно получать id задачи
  и отдельно саму задачу.

* rq
  Как только id задачи был получен воркером он пропадает из очереди и
  помещается в started job registry.  Это сортированное множество
  хранящее в себе id'шники стартованных задач и таймстэмпы,
  позволяющие нам судить о времени выполнения.  Как мы видим у RQ
  отсутствует необходимость второй раз пересылать тело задачи в broker
  целеком, т.к. id храниться отдельн от тела.

* Первый подводный камень
  (скрин вершина айсберга) Сам перенос в обоих случаях выполняется
  неатомарно в две операции.  Если в момент между получением задачи и
  сохранением её во временное хранилище у воркера пропала связь с
  redis'ом - задача может уйти в никуда и оставить кластер в
  неконсистентном состоянии.  Такая реализация acknowledgements не
  настоящая и защищает только от сбоев вида "успели сохранить, а
  умерло всё уже потом".

* Как могло бы быть
  (На айсберге появляются два пункта rpoplpush и lua scripts)
  Использование списков редиса в виде транспорта сообщений вообще
  является очень распространённой практикой.  Судя по всему очень
  распространено и хождение по выше указанным граблям.  rpoplpush
  операция которая выполняет перенос сообщения во временное хранилище
  на сервере и только потом отдаёт сам мессадж воркеру.  Грабли
  настолько распространённые, что в документации редиса у этой команды
  есть пометка специально для разработчиков очередей задач.  Минус у
  данного подхода только один - можно работать одновременно только с
  одной очередью.  Альтернатива - забирать задачи из редиса с помощью
  lua скриптов, выполняемых на сервере.  Привет хранимки.  По сути
  можно эмулировать rpoplpush для нескольких очередей.  Так что, если
  вам на текущий момент нужен железный acknowledge - берите rabbitmq.

* внутри воркера
  (Возможно мужик на заводе) Мы вместе с нашей задачей добрались до
  воркера.  Чтоже происходит с ней внутри.

* celery
  (Мужик собирает сельдерей) Сначала задача попадает в процесс ноду.
  Из ней формируестя объект request.  Далее нода решает, будет ли этот
  request выполнен сейчас или чуть позже.  Счётом времени, обработкой
  событий от сокетов и процессов, исполняющих задачи занимается
  классическая связка event loop + монотонные часы.  Как только
  определённая нами политика назначения задач решает, что задачу пора
  выполнить - она отдаётся уже запущенному процесу воркеру.  Попадает
  он туда с помошью pickle по пайпам операционной системы.  По
  завершению выполнения задачи воркер сам обрабатывает её результат и
  делает acknowledge сообщения.

* rq
  (Мужик собирает редис) Как и в остальном rq устроен в разы проще чем
  celery.  Изначально существует один процесс воркер.  Как только он
  получает задачу, первым делом он сообщает в redis о том, что он всё
  ещё жив и какую именно задачу сейчас выполняет.  Затем выполняется
  форк и задача выполняется в процессе потомке.  Срок жизни
  порождённого процесса равен времени выполнения самой задачи.
  Процесс родитель занимается только тем, что ждёт завершения потомка
  и с самой очередью задач никак не контактирует.  Дочерний процесс
  сам работает с рэдисом, выполняет задачу, следит за таймаутами и
  обрабатывает исключительные ситуации.

* Выполнение задачи
  И вот наконец-то мы начинаем выполнение задачи в дочернем процессе.
  Какие задачи и как мы можем выполнять?  Ясное дело номером один
  стоят простые функции.  Тут всё просто.  Посмотрели какую функцию
  или метод от нас хотят, импортировали необходимый модуль, вызвали
  тело задачи с переданными аргументами и получили возвращаемое
  значение.

* многозадачность
  У данного подхода есть ярко выраженная черта.  Процесс выполняет
  одну задачу одновременно.  Отсюда простое следствие - хорошо для CPU
  bound задач, плохо для задач где много IO.  Если каждая задача по
  большей части занимается тем, что ждёт ответ по сети, то это просто
  растрата машинного времени.  Долго и неэффективно.  И celery и rq
  предоставляют поддержку gevent.  Каждая задача становится
  greenlet'ой и выполняются паралельно.  Так что если gevent как
  технология вас полностью устраивает, то проблем не будет.  А вот как
  быть если мы хотим выполнить не функцию, а например сопрограмму из
  asyncio - другой вопрос.  В данном случае готовых решений нет.  Для
  asyncio я начал пилить aiorq путём полного переписывания rq на
  aioredis.

* Обработка таймаутов
  Теперь к обработке таймаутов.  Мы ведь не хотим, чтобы задачи
  выполнялись слишком долго.  В celery за продолжительностью
  выполнения следит нода, которая посылает воркеру сигнал операционной
  системы.  Обработчиком сигнала как раз и является хэндлер таймаута.
  RQ в этом случае очень похож на celery.  Перед выполнением задачи
  дочерний процесс "заводит себе будильник" средствами операционной
  системы.  После получения аларма так же включается хэндлер
  таймаута.  Какой у данного подхода минус?  Сам сигнал может просто
  не дойти до процесса из-за сбоя в операционной системе.  Или может
  быть проигнорирован, если мы находимся например внутри вызова Сишной
  либы.  Если все плохо, задача повисла, сигнал потерялся, то нода
  celery может убить дочерний процесс деватым килом и тем самым спасти
  ситуацию.  В случае с rq дочерний процесс просто повиснет...

* Rate limits
  Теперь поговорим об искуственных ограничениях, которые мы хотим
  наложить на поток исполнения задач в нашем кластере.  Первое же что
  приходит в голову, ограничить количество конкретных задач за
  интервал времени.  Механизм рэйт лимитов поддерживается только в
  celery и выражается количеством задач в минуту.  Поскольку одна и
  таже задача может попасть в разные очереди в зависимости от
  роутинга, а сам воркер не может повлиять на то, какие именно задачи
  придут из слушаемых очередей, ему ничего не остаётся как принимать
  все возможные задачи.  Внутри ноды происходит рассчёт пропускной
  способности каждой задачи.  Как только он превышен, принятая задача
  откладывается до момента, когда закончится указанный период.  До тех
  пор, сама задача хранится в ноде и на неё не ставится acknowledge.
  Для того, чтобы в это время на воркер мог заниматься полезными
  делами, значение quality of service (он же prefetch count) у
  consumer'а увеличивается на единицу.  В этот слот можгут приходить
  другие задачи.

* Проблемы
  У данного подхода есть заметный минус.  Для задач с низким rate
  limit воркеры могут выгребать большое колличество этих задач из
  broker'а, оставляя их пылиться внутри ноды.  Как только соседний
  воркер освободился от других задач - ему может быть нечего делать.
  Таким образом могут появиться пухнущие ноды и пропускная способность
  кластера может быть заметно ниже, чем позволяет количество нод.

* Как это будет в aiorq
  Поскольку корнем агрегации в RQ является очередь а не задача, то
  логично распространить ограничение rate limit на очередь в целом.
  Поскольку я в aiorq придерживаюсь подхода rpoplpush, из которого
  следует правило "один воркер - одна очередь", то rate limit там
  можно реализовать простым семафором.  Задачи в воркере просто не
  будут браться из очереди, если превышено пороговое значение.

* Предположительное время прибытия
  (табло аэропорта)  Итак как же реализуется выполнение задач "не
  ранее чем?"  В celery eta/countdown лежит одним из полей в payload и
  на работу broker'а никак не влияет.  Произвольные задачи из очереди
  также попадают во внутрь ноды.  Если по часам воркера время
  выполнить задачу ещё не настало, она откладывается до наступления
  заветного момента.  Prefetch limit увеличивается на единицу.  Видим
  ту же самую проблему - возможно пухнущие ноды, которые не делятся с
  другими.

* rq-scheduler
  В rq эта проблема решается дополнительным пакетом rq-scheduler.
  Вместо очереди задачи помещаются в сортированное множество для
  отложенных затач.  Сортировка производится по таймстэмпу того самого
  времени прибытия.  В кластере должен быть запущен отдельный процесс,
  который будет переносить эти задачи в предназначенные им очереди.
  Раз в минуту процесс смотрит, у каких задач прошло предназначенное
  им eta и шедулит их.  У данного подхода плохая точность самого eta,
  так как задачи попадают в конец очереди, когда их eta время уже
  прошло с погрешностью в минуту.

* отмена задач
  Отмена запланированных затач в celery происходит посредством
  рассылки широковещательного сообщения на все воркеры "пропустите эту
  задачу, если вдруг назначат."  Сами воркеры копят этот стэйт у себя
  внутри.  Так же есть возможность хранить это стэйт локально, так
  чтобы он переживал перезапуск воркера.  При этом celery может
  отменить уже запущенную задачу, послав сигнал операционной системы
  воркеру, исполняющему задачу в данный момент.  RQ же просто удаляет
  id задачи из очереди, следовательно ниодин воркер не сможет до неё
  добраться.  Остановки уже запущенных задач не реализовано.

* Представление приметивов
  Celery примечателен разнообразием примитивом в которые можно
  собирать задачи.  Сюда входят link'и, chain'ы, группы и хорды.
  Линк - простой callback.  Если при submit'е задачи, вы указали
  задачу, которую необходимо выполнить следом, то её сигнатура
  храниться отдельным полем в payload сообщения.  После того как
  исходная задача будет выполнена worker'ом в очереди появиться новая,
  созданная из сигнатуры.  Результат выполнения искомой задачи
  хранится в поле аргументов callback'а созданного из сигнатуры.
  Таким образом для выполнения задачи callback'а нет необходимости
  лишний раз тревожить backend.  Chain'ы являются всего лишь небольшим
  DSL для определения последовательностей callback'ов.  Каждая
  сигнатура промежуточного callback'а хранит в себе вложенную
  сигнатуру следующего за ним.  В rq последовательности задач тоже
  имеются.  Зависимые задачи вместо очереди попадают в специальное
  множество с именем соответствующим id зависимости.  Как только
  задача с этим id будет выполнена, искомые задачи будут поставлены в
  очередь.  Группы - исполнение нескольких задач паралельно с
  возможностью получить результаты каждой из задач.  Сама группа при
  этом является простым питоновским объектом и ни в broker'е ни в backend'е
  никак не фигурирует.  И воссоздать группу по id в отличие от задачи
  нельзя.  Теперь самое интересное - хорды - группа, по завершению
  которой выполняется callback.  В каждой задаче из головы хорды лежит
  сигнатура тела.  В самой сигнатуре указано общее число задач в
  голове хорды.  При успешном выполнение каждой задачи из головы в
  backend'е с помошью атомарного инкремента увеличивается счётчик для
  unlock'а хорды.  Та задача, для которой значение счётчика совпадёт
  со значением из сигнатуры, порождат задачу тела хорды.  В RQ к
  сожелению ни групп ни хорд не реализовано, поэтому сравнивать
  несчем.

* масштабируем rabbit
  (Мужик растягивает кролика) Поскольку для нашей распределённой
  системы broker и backend являются едиными точками отказа, хотелось
  бы понять, а можно ли это дело масштабировать?  RabbitMQ умеет из
  коробки горизонтальное масштабирование как между машинами в
  локальной сети, так и между датацентрами.  Как это работает.  Нас
  интересует именно вариант в локальной сети.  Создаётся кластер из
  нескольких нод rabbitmq.  Они начинают общаться между собой
  используя erlang cookie.  По умолчанию реплицируются только
  exchange'и и биндинги, так как в них нет стэйта.  Очереди хранятся
  на ноде, на которой они были впервые декларированы.  Таким образом,
  если ноде поплохело и она упала, все очереди хранящиеся на ней будут
  недоступны.  Неприятная ситуация.  Можно включить режим High
  Availability для очередей.  Например есть нода с декларированной на
  ней очередью.  Мы пушим сообщения, очередь копится, всё работает как
  и должно.  Потом мы деплоим вторую ноду в кластер.  Новые сообщения
  публикуемые в очередь, начинают реплицироваться в новую ноду.  Уже
  существующие на тот момент сообщения продолжают храниться только на
  ноде 1.  Поскольку назначаются сообщения по порядку их прибытия со
  временем разница будет уменьшаться и очереди станут одинаковыми.
  Если же до этого момента первая нода упадёт, назначаться начнут
  сообщения из очереди хранящейся на ноде 2.  Если нода 1 поднимится,
  то имеющаяся разница в сообщениях будет просто выкинута, а нода
  станет репликой ноды 2.  Всё же лучше чем потерять очередь
  полностью.  Осталось поставить сам кластер на какой-нибудь
  балансировщик, типа HAProxy, и прописать его адрес в поле broker'а.

* как это могло бы быть в redis
  (redis blaster) У redis'а имеется экспериментальная поддержка
  кластеризации.  Она добавляет некоторые особенности в используемые
  команды и пока не пользуется особой популярностью как у авторов
  драйверов, так и фрэймворков.  С другой стороны довольно популярный
  подход это шардирование средствами клиента.  Одна из возможных
  реализаций это как раз redis blaster, написанный Армином Ронахером.
  Если вкратце, то мы определяем список нод redis'а, к которым имеем
  доступ.  Далее используя алгоритм консистентного хэша выбираем одну
  ноду, на которую хотим что-то записать.  Как в случае с celery так и
  с rq аргументом для хэширующей функции может служить id задачи.
  Структуры данных типа очереди можно реплицировать на все ноды, саму
  задачу хранить только в одной.  Таким образом при
  пропадании/появлении нод хэш будет перестраиваться.  Проблема
  данного подхода в том, что актуальный список нод необходимо
  поддерживать руками.  Тоесть передеплоивать и перезапускать кластер
  при каждом добавлении redis'а.  Или интегрировать реализацию нашей
  очереди с каким нибудь Service Discovery.  Что-то подобное Эндрю
  Годвин делает для Django Channels.  Шардирование уже есть, но без
  динамической перестройки кластара.

* пара умных мыслей
  О чём было всё выше сказанное.  Хороший инженер всегда знает какие
  последствия несут за собой принимаемые им решения.  А для этого
  необходимо понимать как устроены используемые инструменты.  Будте
  хорошими инженерами.  Можно кидать помедоры.
